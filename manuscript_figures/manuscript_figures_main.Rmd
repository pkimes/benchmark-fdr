---
title: "Manuscript Figures for Genome Biology"
author: "Rafalab"
output: 
    html_document:
        toc: true
        toc_float: true
        highlight: tango
        number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This Rmd generates the main manuscript figures. Additional Rmds
generate the supplementary case study and in silico experiment figures 
(`manuscript_figures.Rmd`) and supplementary case study figures 
(`manuscript_figures_sims.Rmd`). 

# Set up workspace 

```{r Figure2-load-data}
# Load packages and source benchmark FDR
library(tidyr)
library(dplyr)
library(ggplot2)
library(magrittr)
library(cowplot)
library(tibble)
library(ggthemes)
library(grid)
library(SummarizedBenchmark)

## load helper functions
for (f in list.files("../datasets/R", "\\.(r|R)$", full.names = TRUE)) {
    source(f)
}

# Assumes sb objects for the case studies and in silico experiments are in 
# the following location, which contains subfolders
# for each casestudy (if this isn't true, then parsing the case study and 
# dataset names later on will be incorrect)
path <- "../results"

# Also assumes that simulation results summary file is in the following location
# The `result-metrics.rds` was generated in the 
# `datasets/simulations/simulations-summary.Rmd` file.
resmet_file <- file.path("..", "datasets", "simulations", "results-summary", "result-metrics.rds")

# set up results directory
outdir <- "./figures"
dir.create(outdir, showWarnings = FALSE)

# set alpha cutoff for plots that are fixed at a certain value of alpha
alpha.thresh <- 0.05

# methods to include in all figures ( exclude bonferroni and fdrreg-e)
methodset <- c("bh", "ihw", paste0("ihw-a0", 1:9), "ihw-a10", 
               "qvalue", "bl", "bl-df03", "lfdr",
               "fdrreg-t", "ashq", "adapt-glm")
```


We use the standardize candy color scheme and line types for the plots. We'll
add the "lfdr*" method, which indicates lfdr was applied with fewer than 200 
tests per bin (out of 20 bins).

```{r}
col <- as.character(candycols$col)
names(col) <- as.character(candycols$Method)
lty <- as.character(candycols$lty)
names(lty) <- as.character(candycols$Method)
```

To generate the figures in this document, the simulation results must first be aggregated by running the code at `datasets/simulations/simulations-summary.Rmd`.

```{r load-sim-metrics}
resmet <- readRDS(resmet_file)
```

Unfortunately, because the plots in this section illustrate FDR and TPR acorss varying simulation settings rather than varying nominal FDR cutoff, we cannot simply use the `plotsim_average()` function to generate plots. Instead, we define the following helper function to consistently generate plots similar to those output by `plotsim_average()` with arbitrary covariate, e.g. number of tests or proportion of null hypotheses, as the x-axis. The function assumes that the input table only includes FDR or TPR values for each method at a single nominal alpha cutoff. In these figures, we only plot FDR and TPR values at the nominal alpha cutoff of 0.05.

```{r genplot-function}
genplot <- function(tab, cov, type = c("info", "diff"), xt = "", met = c("FDR", "TPR"), ebw = 0.0025) {
    met <- match.arg(met)
    cov <- rlang::enquo(cov)
    type <- match.arg(type)
    if (type == "info") {
        ymean <- rlang::quo(mean.info)
        yse <- rlang::quo(se.info)
    } else if (type == "diff") {
        ymean <- rlang::quo(mean.diff)
        yse <- rlang::quo(se.diff)
    }        
    gp <- dplyr::filter(tab, key == met) %>%
        ggplot(aes(x = !!cov, y = !!ymean, color = Method, group = Method)) +
        geom_line(aes(linetype = Method), alpha = 0.85) +
        geom_errorbar(aes(ymin = !!ymean - !!yse, ymax = !!ymean + !!yse), width = ebw, alpha=0.5) +
        scale_linetype_manual(values = lty) + 
        scale_color_manual(values = col) +
        expand_limits(y = 0) +
        theme_classic() +
        theme(axis.title = element_text(face = "bold", size = 11),
              plot.title = element_text(face = "bold", size = 12))
    if (type == "diff") {
        gp <- gp + geom_hline(yintercept = 0, lty = 2, color = "blue", alpha = 1/2)
        gp <- gp + scale_y_continuous(bquote(Delta ~ .(met) ~ (informative-uninformative)),
                                      labels = scales::percent)
    } else {
        gp <- gp + scale_y_continuous(met, labels = scales::percent)
        if (met == "FDR") {
            if (rlang::quo_name(cov) == "alpha") {
                gp <- gp + geom_abline(lty = 2, color = "blue", alpha = 1/2) 
            } else {
                gp <- gp + geom_hline(yintercept = 0.05, lty = 2, color = "blue", alpha = 1/2) 
            }
        }
    }
    gp
}
```


# Figure 1 - FDR

This figure contains the main FDR results for the simulations and *in silico* 
experiments. Panel (A, left) contains the FDR results for a representative setting of
the yeast *in silico* experiments, showing that all methods control FDR. Panel 
(A, right) contains the FDR results for the polyester read count simulation, showing that
most methods control the FDR, with the exception of lfdr and ash, which have slightly
inflated FDR. Panels (B) contains the FDR results for simulations that 
vary the number of hypotheses and the proportion of null hypotheses, respectively. 
These results show that ash and lfdr fail to control FDR under certain settings. 

```{r Figure1, fig.width = 7.5, fig.height = 6.5}
# FDR in in silico experiments across alpha values 
## Figure 1A: FDR of methods in representative yeast setting at varying alpha levels
objects <- list.files( path, recursive=TRUE, pattern="rds", full.names=TRUE )
resfile <- objects[grepl("yeast-", objects) & 
                   grepl("de5", objects) & 
                  !grepl("uninf", objects)] 
de5 <- readRDS(file=resfile)
res5d <- plotsim_standardize(de5, alpha = seq(0.01, 0.10, 0.01)) %>% 
  filter(blabel %in% methodset)
p1a <- plotsim_average(res5d, met="FDR",
                merge_ihw = TRUE, errorBars=TRUE) +
      ggtitle("Resampling with spike-ins") +
      scale_x_continuous(expression(paste(bold(alpha), bold(" level"))),
                         breaks=seq(0, 1, by=0.02)) +
      scale_y_continuous("FDR", labels=scales::percent, breaks=seq(0, 1, by=0.02)) +
      expand_limits(y=0.11) +
      theme(plot.title = element_text(face = "bold", size = 12)) 

## Figure 1B: FDR of methods in representative polyester setting at varying alpha levels
objects <- list.files( path, recursive=TRUE, pattern="rds", full.names=TRUE )
resfile <- objects[grepl("polyester-", objects) & 
                   grepl("de5", objects) & 
                  !grepl("uninf", objects)] 
de5 <- readRDS(file=resfile)
res5dp <- plotsim_standardize(de5, alpha = seq(0.01, 0.10, 0.01)) %>% 
  filter(blabel %in% methodset)
p1b <- plotsim_average(res5dp, met="FDR",
                merge_ihw = TRUE, errorBars=TRUE) +
      ggtitle("Polyester count simulation") +
      scale_x_continuous(expression(paste(bold(alpha), bold(" level"))),
                         breaks=seq(0, 1, by=0.02)) +
      scale_y_continuous("", labels=scales::percent, breaks=seq(0, 1, by=0.02)) +
      expand_limits(y=0.11) +
      theme(plot.title = element_text(face = "bold", size = 12)) + 
  theme(legend.position="none") 

p1abTitle <- ggdraw() +
    draw_label(expression(paste(bold("FDR control in RNA-seq "), 
                                bolditalic("in silico"), bold(" experiments"))))

# Panels C and D -> FDR in sims across settings at a single specified alpha
## Figure 1C: FDR of methods across varying number of tests at alpha.thresh
res_ntests <- dplyr::filter(resmet, setting == "varyingntests", 
                            alpha == alpha.thresh, Method %in% methodset) 
p1c <- genplot(res_ntests %>% filter(ntests >= 4000 | Method != "lfdr"), 
               cov = ntests, met = "FDR", ebw = 0.1) +
    scale_x_continuous("Number of tests", trans = "log10",
                       breaks = c(1e2, 5e2, 1e3, 5e3, 1e4, 5e4),
                       labels = c("100", "500", "1e3", "5e3", "1e4", "5e4")) +
    guides(color = FALSE, linetype = FALSE) +
    scale_y_continuous("FDR", labels = scales::percent, breaks=seq(0,1,by=0.02)) +
    ggtitle("Varying number of tests") +
    coord_cartesian(ylim = c(0,0.12)) + 
    geom_line(data = res_ntests %>% 
                filter(ntests <= 5000 & Method == "lfdr", performanceMetric == "FDR"),
              aes(x = ntests, y = mean.info), 
              linetype = "dashed", color = "dodgerblue3", alpha = 0.88) +
    geom_errorbar(data = res_ntests %>% 
                 filter(ntests <= 5000 & Method == "lfdr", performanceMetric == "FDR"),
                 aes(ymin = mean.info - se.info, ymax = mean.info + se.info), width = 0.1, alpha=0.5)

## Figure 1D: FDR of methods across varying null proportion at alpha.thresh
res_pi0 <- dplyr::filter(resmet, setting == "varyingpi0", 
                         alpha == alpha.thresh, Method %in% methodset,
                         pi0 >= 10) # restrict to pi0 at least 10%
p1d <- genplot(res_pi0, cov = 100-pi0, met = "FDR", ebw = 2.5) +
    scale_x_continuous("Proportion non-null",
                       breaks = 100 - c(seq(10, 90, by = 10), 95, 99)) + 
  guides(color = FALSE, linetype = FALSE) + 
  ggtitle("Varying non-null proportion") +
  scale_y_continuous("", labels = scales::percent, breaks=seq(0,1,by=0.02), 
                       limits=c(0,.12)) 

p1cdTitle <- ggdraw() +
    draw_label(expression(paste(bold("FDR across simulation settings ("), 
                                bold(alpha), bold(" = 0.05)"))))

## pull Figure 1 together
top <- plot_grid(p1a + theme(legend.position="none"), p1b, nrow = 1)
bot <- plot_grid(p1c, p1d, nrow = 1)
Fig1 <- plot_grid(p1abTitle, top, p1cdTitle, bot, nrow=4, 
                  rel_heights = c(0.1, 1, 0.1, 1),
                  labels = c("A", "", "B", ""))
Fig1 <- plot_grid(Fig1, get_legend(p1a), rel_widths = c(1, .2))
Fig1
ggsave(file.path(outdir, "Fig1.pdf"), width=7.5, height=6.5)
```

# Figure 2 - Power

This figure contains the main TPR results for the simulations and *in silico* 
experiments, and is analagous to Figure 1. 
Panel (A) contains the TPR results for a representative setting of
the yeast *in silico* experiments and polyester simulations, showing that in 
general, modern FDR-controlling methods have modestly higher power than classic methods. 
In addition, lfdr, fdrreg-t, and adapt tend to have highest power compared to other
methods.
Panel (B) contains the TPR results for simulations that 
vary the number of hypotheses and the proportion of null hypotheses, respectively. 
These results show that adapt and lfdr are very conservative under some settings 
of the number of tests, and that the relative ranking of methods is somewhat 
robust under varying proportions of null hypotheses. 

```{r Figure2, fig.width = 7.5, fig.height = 6.5}
# TPR in in silico experiments across alpha values 
## Figure 2A: TPR of methods in representative yeast setting at varying alpha levels
p2a <- plotsim_average(res5d, met="TPR",
                merge_ihw = TRUE, errorBars=TRUE) +
      ggtitle("Resampling with spike-ins") +
      scale_x_continuous(expression(paste(bold(alpha), bold(" level"))),
                         breaks=seq(0, 1, by=0.02)) +
      scale_y_continuous("TPR", labels=scales::percent, breaks=seq(0, 1, by=0.05)) +
      theme(plot.title = element_text(face = "bold", size = 12)) 

## Figure 2B: TPR of methods in representative polyester setting at varying alpha levels
p2b <- plotsim_average(res5dp, met="TPR",
                merge_ihw = TRUE, errorBars=TRUE) +
      ggtitle("Polyester count simulation") +
      scale_x_continuous(expression(paste(bold(alpha), bold(" level"))),
                         breaks=seq(0, 1, by=0.02)) +
      scale_y_continuous("", labels=scales::percent, breaks=seq(0, 1, by=0.05)) +
      theme(plot.title = element_text(face = "bold", size = 12)) + 
  theme(legend.position="none") 

p2abTitle <- ggdraw() +
    draw_label(expression(paste(bold("TPR in RNA-seq "), 
                                bolditalic("in silico"), bold(" experiments"))))

# Panels C and D -> TPR in sims across settings at a single specified alpha
## Figure 2C: TPR of methods across varying number of tests at alpha.thresh
res_ntests <- dplyr::filter(resmet, setting == "varyingntests", 
                            alpha == alpha.thresh, Method %in% methodset)
p2c <- genplot(res_ntests %>% filter(ntests >= 4000 | Method != "lfdr"),
               cov = ntests, met = "TPR", ebw = 0.1) +
    scale_x_continuous("Number of tests", trans = "log10",
                       breaks = c(1e2, 5e2, 1e3, 5e3, 1e4, 5e4),
                       labels = c("100", "500", "1e3", "5e3", "1e4", "5e4")) +
    guides(color = FALSE, linetype = FALSE) +
    scale_y_continuous("TPR", labels = scales::percent, breaks=seq(0,1,by=0.1)) +
    ggtitle("Varying number of tests")  + 
    geom_line(data = res_ntests %>% 
                filter(ntests <= 5000 & Method == "lfdr", performanceMetric == "TPR"),
              aes(x = ntests, y = mean.info), 
              linetype = "dashed", color = "dodgerblue3", alpha = 0.88) +
    geom_errorbar(data = res_ntests %>% 
                 filter(ntests <= 5000 & Method == "lfdr", performanceMetric == "TPR"),
                 aes(ymin = mean.info - se.info, ymax = mean.info + se.info), width = 0.1, alpha=0.5)

## Figure 1D: FDR of methods across varying null proportion at alpha.thresh
res_pi0 <- dplyr::filter(resmet, setting == "varyingpi0", 
                         alpha == alpha.thresh, Method %in% methodset,
                         pi0 >= 10) # restrict to pi0 at least 10%
p2d <- genplot(res_pi0, cov = 100-pi0, met = "TPR", ebw = 2.5) +
    scale_x_continuous("Proportion non-null",
                       breaks = 100 - c(seq(10, 90, by = 10), 95, 99)) + 
  guides(color = FALSE, linetype = FALSE) + 
  ggtitle("Varying non-null proportion") +
  scale_y_continuous("", labels = scales::percent, breaks=seq(0,1,by=0.20)) 

p2cdTitle <- ggdraw() +
    draw_label(expression(paste(bold("TPR across simulation settings ("), 
                                bold(alpha), bold(" = 0.05)"))))

## pull Figure 1 together
top <- plot_grid(p2a + theme(legend.position="none"), p2b, nrow = 1)
bot <- plot_grid(p2c, p2d, nrow = 1)
Fig2 <- plot_grid(p2abTitle, top, p2cdTitle, bot, nrow=4, 
                  rel_heights = c(0.1, 1, 0.1, 1),
                  labels = c("A", "", "B", ""))
Fig2 <- plot_grid(Fig2, get_legend(p2a), rel_widths = c(1, .2))
Fig2
ggsave(file.path(outdir, "Fig2.pdf"), width=7.5, height=6.5)
```


# Figure 3 - Robustness

# Figure 4 - Applicability

This figure shows the applicability of each of the methods to a variety of data types
within the case studies, as well as to different types of statistical tests both 
within the case studies and simulation settings. Panel (A) displays the performance 
across different test statistic distributions, and panel (B) displays the performance
across different case studies. 

```{r Figure4, fig.width = 11, fig.height = 11}
res_noise <- dplyr::filter(resmet, setting == "informative-cubic") %>%
  filter(Method %in% methodset)

## Distribution of unimodal effect sizes (based on random samples)
set.seed(100)
tsdists <- bind_rows(dplyr::mutate(simIteration(1, NULL, m = 2e4, pi0 = 0.9,
                                                es_dist = rnorm_generator(3),
                                                ts_dist = rnorm_perturber(1),
                                                null_dist = rnorm_2pvaluer(1),
                                                icovariate = runif, execute = FALSE),
                                   dist = "\"Distribution: \" * N(0, 1)"),
                     dplyr::mutate(simIteration(1, NULL, m = 2e4, pi0 = 0.9,
                                                es_dist = rnorm_generator(3),
                                                ts_dist = rt_perturber(5),
                                                null_dist = rt_2pvaluer(5),
                                                icovariate = runif, execute = FALSE),
                                   dist = "\"Distribution: \" * t[5]"),
                     dplyr::mutate(simIteration(1, NULL, m = 2e4, pi0 = 0.9,
                                                es_dist = rnorm_generator(3),
                                                ts_dist = rt_perturber(11),
                                                null_dist = rt_2pvaluer(11),
                                                icovariate = runif, execute = FALSE),
                                   dist = "\"Distribution: \" * t[11]"),
                     dplyr::mutate(simIteration(1, NULL, m = 2e4, pi0 = 0.9,
                                                es_dist = function(x) { abs(rnorm_generator(15)(x)) },
                                                ts_dist = rchisq_perturber(4),
                                                null_dist = rchisq_pvaluer(4),
                                                icovariate = runif, execute = FALSE),
                                   dist = "\"Distribution: \" * {\n    chi^2\n}[4]"))
tsdists <- dplyr::mutate(tsdists, dist = factor(dist, levels = levels(factor(dist))[c(2, 3, 4, 1)]))
tsdists <- dplyr::rename(tsdists, truth = qvalue)
tsdists <- dplyr::mutate(tsdists, truth = factor(truth, levels = 0:1, labels = c("null", "non-null")))

## Figure 4A: Performance across distribution of test statistics (based on single replicate)
p4a <- ggplot(tsdists, aes(x = test_statistic, y=..count..,
                            group = truth, color = truth)) +
    stat_density(geom = "line", position = "identity", adjust = 1/2) + 
    theme_classic() +
    scale_color_brewer("Truth", palette = "Set1", direction = -1) + 
    scale_x_continuous("test statistic (single replicate)") +
    coord_cartesian(xlim = c(-5, 25)) + 
    theme(axis.title = element_text(face = "bold", size = 10),
          plot.title = element_text(face = "bold", size = 14)) +
    facet_grid(. ~ dist, labeller = label_parsed) 
p4a <- plot_grid(p4a, genplot(res_noise, cov = alpha, met = "FDR") +
                   facet_grid(. ~ dist, labeller = label_parsed) +
                   scale_x_continuous(expression(paste(bold(alpha), bold(" level"))),
                         breaks=seq(0, 1, by=0.02)) +
                   expand_limits(x = 0) , axis = "trbl", align="hv",
                 nrow=2, rel_heights = c(0.75,1))

Titlep4a <- ggdraw() +
    draw_label(expression(paste(bold("FDR across test statistic distributions in simulation"))))
p4a <- plot_grid(Titlep4a, p4a, nrow = 2, rel_heights = c(0.1,1), labels = c("A", ""))

## Figure 4B: Case study heatmap demonstrating variability in applicability

## read list of case study results
objects <- list.files(path, recursive=TRUE, pattern="rds", full.names=TRUE)

## exclude yeast and polyester simulations, as well as uninformative covariate
## analyses
objects <- objects[!grepl("yeast", objects) & !grepl("polyester", objects) &
                   !grepl("uninf", objects)]

## create shorter names for case studies
object_labs <- gsub("\\.rds", "", basename(objects))
object_labs <- gsub("-benchmark", "", object_labs)

## read in case study results (proportion of rejects vs. case study max)
objdat <- tidy_df(objects=objects, colLabels=object_labs, 
                  fill="propMaxRejections", annotate=NULL,
                  alpha =0.10)
objdat <- as_tibble(objdat)
objdat <- tidyr::complete(objdat, method, casestudy)

## exclude 'enigma-so4-otus' results with no significant calls
objdat <- dplyr::filter(objdat, casestudy != "enigma-so4-otus")

## create table of case study-to-assay mapping
studies <- tibble(
    casestudy = c("cbp-csaw", "h3k4me3-csaw", "human", "mouse", "bmi-maf", "bmi-samplesize",
                  "enigma-al-otus", "enigma-ph-otus", "enigma-so4-otus", "baxter-genus", 
                  "goodrich-genus", "papa-genus", "schubert-otus", "brain", "mir200c",
                  "human-mast-det", "human-mast-mean", "human-scdd-det",
                  "human-scdd-mean", "human-wilcox-det", "human-wilcox-mean",
                  "mouse-mast-det", "mouse-mast-mean", "mouse-scdd-det",
                  "mouse-scdd-mean", "mouse-wilcox-det", "mouse-wilcox-mean"),
    assay = c(rep("ChIP-seq", 2), rep("GSEA", 2), rep("GWAS", 2), rep("Microbiome", 7),
              rep("RNA-seq", 2), rep("scRNA-seq", 12)))

## add assay labels to results table
objdat <- left_join(objdat, studies, by = "casestudy")
objdat <- dplyr::filter(objdat, !is.na(assay))

## create table of rejected proportion for top methods per case study
objdat_props <- dplyr::group_by(objdat, casestudy)
objdat_props <- dplyr::filter(objdat_props, nrejects == max(nrejects, na.rm = TRUE))
objdat_props <- dplyr::ungroup(objdat_props)
objdat_props <- dplyr::mutate(objdat_props, lab = paste0(100*round(propPossible, 4), "%"))
objdat_props$plotrow <- "real"

## create table of total tests for each case study
objdat_tab <- dplyr::select(objdat_props, casestudy, nrejects, propPossible, assay)
objdat_tab <- dplyr::distinct(objdat_tab)
objdat_tab <- dplyr::mutate(objdat_tab, `Total Tests` = scales::comma(round(nrejects / propPossible)))
objdat_tab <- dplyr::select(objdat_tab, casestudy, assay, `Total Tests`) 
objdat_tab <- tidyr::gather(objdat_tab, method, cnt, -casestudy, -assay)

## hack to get total counts and heatmap in same plot
objdat_joint <- bind_rows(list(real = objdat, fake = objdat_tab), .id = "plotrow")

# filter for methods in methodset
objdat_joint <- filter(objdat_joint, method %in% c(methodset, "Total Tests"))

## specify method order
method_order <- c("bh", "ihw", "qvalue", "bl", "adapt-glm", "lfdr", "fdrreg-t", "ashq")
objdat_joint <- dplyr::mutate(objdat_joint, method = factor(method, levels = c(method_order, "Total Tests")))

# add notation for missing because "shouldn't"
objdat_joint <- objdat_joint %>% 
  mutate(should = ifelse(method == "lfdr" & is.na(nrejects), "*", ""))

p4b <- ggplot(objdat_joint, aes(x = casestudy, y = method, fill = propMaxRej)) +
    scale_x_discrete("Case Study", expand = c(0, 0)) +
    scale_y_discrete("Method", expand = c(0, 0)) +
    geom_tile() +
    geom_text(aes(label = lab), data = filter(objdat_props, method %in% methodset),
              size = 1.8, color = "white") +
    geom_text(aes(label = should), size = 5, color = "black") +
    geom_tile(data = filter(objdat_joint, plotrow == "fake"), fill = "white") + 
    geom_text(aes(label = cnt), data = dplyr::filter(objdat_joint, !is.na(cnt)), size = 2) + 
    scale_fill_distiller("% Rejected\n(relative to max)",
                         palette = "Blues", direction = 1, limits = c(0, 1),
                         labels = scales::percent) +
    facet_grid(plotrow ~ assay, scales = "free", space = "free") +
    theme_bw() + 
    theme(axis.text.x = element_text(angle = 90, vjust = 1/2, hjust = 1),
          strip.text.y = element_blank(),
          legend.position = c(0,-0.32), legend.justification = c(0, 1),
          legend.direction = "horizontal",
          legend.text = element_text(size = 7),
          legend.title = element_text(size = 9),
          legend.margin = margin(6, 10, 6, 10))
Titlep4b <- ggdraw() +
    draw_label(expression(paste(bold("Number of rejections in case studies"))))
p4b <- plot_grid(Titlep4b, p4b, nrow = 2, rel_heights = c(0.075,1), 
                 labels = c("B", ""))

## pull Figure 4 together
Fig4 <- plot_grid(p4a, p4b, ncol = 1, rel_heights = c(1,1))
Fig4
ggsave(file.path(outdir, "Fig4.pdf"), width = 11.2, height = 10.5)
```

# Figure 5 - Summary

The summary of recommendations figure is drawn manually.

# Session information

```{r}
sessionInfo()
```
